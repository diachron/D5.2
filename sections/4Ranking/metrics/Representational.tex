%!TEX root = ../../../diachron-D5_2.tex

%~(required for: \textbf{GEN}, \textbf{DP}, \textbf{EBI})
\subsubsection{Representational Category}
\label{sec:Representational} 
Representational dimensions reflect the quality aspects like conciseness, consistency and interpretability of information.

\paragraph{Representational Conciseness Dimension}~\\ % dimension name
Representational conciseness is determined by how compact, properly formatted and clear is the data. As defined by Pipino et al. in \cite{Pipino2002}, this dimension is defined as ``the extent to which information is compactly represented''. 

\paragraph{Short URIs}~\\
% background for the metric
URIs play a key role in how information is represented in Linked Data resources, as they are used to name the entities being described. Therefore, having compact, well formatted URIs has a positive effect in the clearness and conciseness of data. 
As suggested by \cite{Hogan2012:LDC}, data providers that locally mint (on average) shorter URIs are deemed as being more compliant with Linked Data best practices.

% short description
\begin{mdframed}[style=metricdefinition]
\emph{Detects whether, in average, short URIs are being used, which suggests that information is compactly represented and that readability is favored.}
\end{mdframed}

% pseudocode
Implementation details regarding these metric are provided in algorithm~\ref{alg:shortURIs}. All URIs identifying instances, that are defined locally, are considered by the metric. The calculation is performed as the average of the lengths of the URIs corresponding to the subjects of all instance declarations (i.e. statements using the \textit{rdf:type} predicate).
\begin{algorithm}
\caption{Short URIs Algorithm} \label{alg:shortURIs}
\begin{algorithmic}[1]
\Procedure{init}{}
\State accumulatedURIsLength = 0;
\State countLocallyDefURIs = 0;
\EndProcedure
\Procedure{compute}{$\langle?s,?p,?o,?g\rangle$}
\If {equalsURI(?p, rdf:type) \&\& isURI(?s)} 
\State accumulatedURIsLength += lengthOfURI(?s);
\State countLocallyDefURIs++;
\EndIf ~\\
\EndProcedure
\end{algorithmic}
\end{algorithm}
% metric value, range and rating
The metric will return the average length of all the URIs locally defined in the dataset. The expected range is a real number in the range $[0, +\infty)$. Lower values represent better rankings.
% end-of Short URIs Metric
\todo{CL: Can't we group this differently?  We currently have paragraphs both for dimensions and for metrics. - JD: ideally yes}\paragraph{Understandability Dimension}
Understandability is the quality of information that enables users to comprehend its meaning. 
It is an ultimate prerequisite for information consumer. 
The better users understand data, the more effectively they can use it. 

\paragraph{Empty Annotation Value}~(required for: \textbf{DP}, \textbf{EBI})~\\
In some languages, eg. OWL, annotation properties are distinguished.
Annotation properties are predicates that provide informal documentation annotations about ontologies, statements, or IRIs. 
A simple example for annotation property is \textit{rdfs:comment} which is used to provide a comment. 
%Unfortunately annotation properties are often used with empty literal values that cause inconsistences in data.
The problem can be solved by the corresponding triples or by replacing empty literals by annotation strings.
The following annotation properties were used in this metric:
\begin{itemize}
\item \textit{skos:altLabel}
\item \textit{skos:hiddenLabel}
\item \textit{skos:prefLabel}
\item \textit{skos:changeNote}
\item \textit{skos:definition}
\item \textit{skos:editorialNote}
\item \textit{skos:example}
\item \textit{skos:historyNote}
\item \textit{skos:note}
\item \textit{skos:scopeNote}
\item \textit{dcterms:description}
\item \textit{dc:description}
\item \textit{rdfs:label}
\item \textit{rdfs:comment}
\end{itemize}

% short description
\begin{mdframed}[style=metricdefinition]
\emph{Measures a percentage of triples whose property is an annotation property and whose object is an empty string.}

\end{mdframed}

The algorithm \ref{lst:emptyAnnotationValue} provides detailed description of metric computation. 
% pseudocode
\begin{algorithm}
\caption{Empty Annotation Value Algorithm}\label{lst:emptyAnnotationValue}
\begin{algorithmic}[1]
\Procedure{init}{}
\State totalAnnotations = 0 ;
\State emptyAnnotations = 0 ;
\EndProcedure

\Procedure{compute}{$\langle?s,?p,?o,?g\rangle$}
\If {isAnnotation(?p)} totalAnnotations++; \EndIf
\If {isEmpty(?o)} emptyAnnotations++ ; \EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}

The metric gives a percentage (as a decimal) in the range of $[0,\ldots,1]$, where 0 indicates the best quality.

\paragraph{Whitespace in Annotation}~\\
In contrast to the previous metric which identifies triples with empty annotation value, this metric deals with the case when the annotation value is available, but contains leading or trailing whitespaces.
The metric is defined as follows:

% short description
\begin{mdframed}[style=metricdefinition]
\emph{Calculates the ratio of annotations with leading or trailing whitespace to all annotations in the data set.}
\end{mdframed}

A predefined list of annotation properties, described in the previous metric, are used. 

% pseudocode
\begin{algorithm}
\caption{Whitespace in Annotation Algorithm}\label{lst:whitespace}
\begin{algorithmic}[1]
\Procedure{init}{}
\State totalAnnotations = 0 ;
\State whitespaceInAnnotations = 0 ;
\EndProcedure

\Procedure{compute}{$\langle?s,?p,?o,?g\rangle$}
\If {isAnnotation(?p)} totalAnnotations++; \EndIf
\If {containsLeadingORTrailingWhitespace(?o)} whitespaceInAnnotations++ ; \EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}

The metric value ranges between $[0,\ldots,1]$, where  0 indicates that data set is free of leading or trailing whitespace in annotations.

\paragraph{Labels Using Capitals}~\\
This metric identifies the triples with label property whose object uses a bad style of capitalisation. 
We define ``bad'' capitalisation as ``camel case'' where compound words or phrases  are written such that each next word or abbreviation begins with a capital letter, e.g. \textit{InterestingThing}.
Regular expression rules are defined for this metric.
The following widely used label properties are considered by the metric:
\begin{itemize}
\item \textit{skos:altLabel}
\item \textit{skos:hiddenLabel}
\item \textit{skos:prefLabel}
\item \textit{rdfs:label}
\end{itemize}

\begin{mdframed}[style=metricdefinition]
\emph{Calculates the ratio of labels with ``bad capitalisation'' to all labels}
\end{mdframed}

% pseudocode
\begin{algorithm}
\caption{Labels Using Capitals Algorithm}\label{lst:badCapitals}
\begin{algorithmic}[1]
\Procedure{init}{}
\State totalLabels = 0 ;
\State badCapitalisedLabels = 0 ;
\EndProcedure

\Procedure{compute}{$\langle?s,?p,?o,?g\rangle$}
\If {isLabel(?p)} totalLabels++; \EndIf
\If {isBadCapitalised(?o)} badCapitalisedLabels++ ; \EndIf
\EndProcedure
\end{algorithmic}
\end{algorithm}

\paragraph{Human Readable Labelling}~(required for: \textbf{DP}, \textbf{EBI})~\\
Having human readable labels enable human consumers to better understand the data.

\begin{mdframed}[style=metricdefinition]
\emph{Measures the percentage of entities having a $\langle$rdfs:label$\rangle$ or $\langle$rdfs:comment$\rangle$ defined}
\end{mdframed}

\begin{algorithm}
\caption{Human Readable Labelling Metric}
\begin{algorithmic}[1]
\Procedure{compute}{$\langle?s,?p,?o,?g\rangle$}
\If {?p is rdf:type} instanceMap.put(?s,0) \EndIf
\If {(?p is rdfs:label $\vee$ ?p is rdfs:comment) $\wedge$ isNotEmptyLiteral(?o)} instanceMap.update(?s,humanLabel++);   \EndIf 
\EndProcedure
\end{algorithmic}
\end{algorithm}

The metric returns a value between [0..1]. This value is calculated by finding a ratio of total number of human readable labels against total number of instances.

\paragraph{Low Blank Node Usage}~(required for: \textbf{DP}, \textbf{EBI})~\\
Blank nodes reduce the understandability of a dataset.
The lower the number of blank nodes is, the higher the quality is.

\begin{mdframed}[style=metricdefinition]
\emph{Provides a measure calculating the number of blank nodes used in a dataset.}
\end{mdframed}

\begin{algorithm}
\caption{Human Readable Labelling Metric}
\begin{algorithmic}[1]
\Procedure{compute}{$\langle?s,?p,?o,?g\rangle$}
\If {blankNode(?s)} blankNodes++; \EndIf
\If {blankNode(?o)} blankNodes++;   \EndIf 
\EndProcedure
\end{algorithmic}
\end{algorithm}

The metric returns a value between [0..1], i.e. the result of dividing the number of blankNodes against the total number of non-literal subject and object entities. The lowest the score, the better.
%%%%%%% Bibliography

% Hogan2012 : Aidan Hogan and JÃ¼rgen Umbrich and Andreas Harth and Richard Cyganiak and Axel Polleres and Stefan Decker. An empirical survey of Linked Data conformance. Web Semantics: Science, Services and Agents on the World Wide Web, 2012%